{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevinouio/MSU-AI-Building-Classification/blob/main/AI_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "JUgINgt8wq2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Including necessary libraries and file paths."
      ],
      "metadata": {
        "id": "ATbYx9-wzYNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Path to your saved model (replace with the actual path)\n",
        "model_path = '/content/drive/MyDrive/ModelsRes/model_epoch_12.h5'\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your Google Drive folder\n",
        "drive_folder = '/content/drive/MyDrive/CheckpointsResNet50/'\n",
        "\n",
        "# Define the path to save the models\n",
        "model_save_folder = '/content/drive/MyDrive/ModelsRes/'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(model_save_folder):\n",
        "    os.makedirs(model_save_folder)\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(drive_folder):\n",
        "    os.makedirs(drive_folder)"
      ],
      "metadata": {
        "id": "MZPCw6IfzXok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Custom Callbacks"
      ],
      "metadata": {
        "id": "JAWEbNAi0ImC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfusionMatrixCallback(Callback):\n",
        "    def __init__(self, validation_generator, class_indices):\n",
        "        super().__init__()\n",
        "        self.validation_generator = validation_generator\n",
        "        self.class_indices = class_indices\n",
        "        self.class_names = list(class_indices.keys())  # List of class names\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Predict on validation data\n",
        "        val_labels = self.validation_generator.classes\n",
        "        val_preds = self.model.predict(self.validation_generator)\n",
        "        val_pred_classes = np.argmax(val_preds, axis=1)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(val_labels, val_pred_classes)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=self.class_names)\n",
        "        disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
        "        plt.title(f'Confusion Matrix after Epoch {epoch + 1}')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "class ResetValidationDataCallback(Callback):\n",
        "    def __init__(self, validation_datagen, data_dir, img_height, img_width, batch_size):\n",
        "        super().__init__()\n",
        "        self.validation_datagen = validation_datagen\n",
        "        self.data_dir = data_dir\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch_counter = 0  # Keeps track of the epochs\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.epoch_counter += 1\n",
        "        # Change validation data after every 12 epochs\n",
        "        if self.epoch_counter % 10 == 0:\n",
        "            print(f'Changing validation data at epoch {epoch + 1}')\n",
        "            # Reload the validation data\n",
        "            self.model.validation_data = self.validation_datagen.flow_from_directory(\n",
        "                self.data_dir,\n",
        "                target_size=(self.img_height, self.img_width),\n",
        "                batch_size=self.batch_size,\n",
        "                class_mode='categorical',\n",
        "                subset='validation'\n",
        "            )\n",
        "\n",
        "\n",
        "class SaveBestEveryEpoch(Callback):\n",
        "    def __init__(self, save_dir, verbose=1):\n",
        "        super(SaveBestEveryEpoch, self).__init__()\n",
        "        self.save_dir = save_dir\n",
        "        self.verbose = verbose\n",
        "        self.best_loss = np.inf\n",
        "        self.block_counter = 1  # Keeps track of 5-epoch blocks\n",
        "        self.best_weights = None  # Best weights for each block\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_loss = logs.get('val_loss')\n",
        "\n",
        "        # Save the model for the current epoch\n",
        "        model_save_path = os.path.join(self.save_dir, f'model_epoch_{epoch + 1}.h5')\n",
        "        self.model.save(model_save_path)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"\\nModel saved at the end of Epoch {epoch + 1} with val_loss: {current_loss:.4f}\")\n",
        "\n",
        "        # Track and save the best model within the current 5-epoch block\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.best_weights = self.model.get_weights()\n",
        "\n",
        "        # After every 5th epoch, save the best model in the block and reset\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            block_save_path = os.path.join(self.save_dir, f'best_model_block_{self.block_counter}.h5')\n",
        "            self.model.set_weights(self.best_weights)  # Set the model to the best weights in this block\n",
        "            self.model.save(block_save_path)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"\\nBest model from block {self.block_counter} saved with val_loss: {self.best_loss:.4f}\")\n",
        "\n",
        "            # Reset for the next block\n",
        "            self.block_counter += 1\n",
        "            self.best_loss = np.inf  # Reset best loss for the next block\n",
        "            self.best_weights = None  # Reset best weights for the next block"
      ],
      "metadata": {
        "id": "ztekF5WS0MUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and preprocess the dataset"
      ],
      "metadata": {
        "id": "ni6XO06k0gaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data_dir = '/content/drive/MyDrive/AIDataset'\n",
        "img_height, img_width = 512, 512\n",
        "batch_size = 32\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # 20% of data will be used for validation\n",
        ")\n",
        "\n",
        "# Train and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(train_generator.class_indices)"
      ],
      "metadata": {
        "id": "78w4n07p0kMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define ResNet34 Model"
      ],
      "metadata": {
        "id": "YmMGAZ180w5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom ResNet34 architecture\n",
        "def ResNet34(input_shape=(512, 512, 3), classes=10):\n",
        "    base_model = tf.keras.applications.ResNet50(\n",
        "        weights='imagenet', include_top=False, input_shape=input_shape\n",
        "    )  # Use ResNet50 and customize the number of layers to mimic ResNet34\n",
        "\n",
        "    # Remove deeper layers to simulate ResNet34\n",
        "    base_model = tf.keras.Model(inputs=base_model.input, outputs=base_model.layers[-34].output)\n",
        "\n",
        "    return base_model\n",
        "\n",
        "# Define the full model structure using ResNet34\n",
        "base_model = ResNet34(input_shape=(img_height, img_width, 3), classes=num_classes)\n",
        "\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    model = load_model(model_path)  # Load the complete model including architecture and weights\n",
        "else:\n",
        "    base_model = ResNet34(input_shape=(img_height, img_width, 3), classes=num_classes)\n",
        "    model = tf.keras.models.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model with the custom learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "k8mVf7rJ1FZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "CRIOLKZL1P0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define learning rate scheduler\n",
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "class ConfusionMatrixCallback(Callback):\n",
        "    def __init__(self, validation_data, class_indices):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data  # Generator\n",
        "        self.class_indices = class_indices  # Class mapping\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_labels = self.validation_data.classes  # True labels from validation set\n",
        "        val_preds = self.model.predict(self.validation_data)  # Predictions for validation set\n",
        "        val_preds_classes = np.argmax(val_preds, axis=1)  # Convert predictions to class labels\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(val_labels, val_preds_classes)\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=self.class_indices)\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f'Confusion Matrix after Epoch {epoch + 1}')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Validation data generator (to be reshuffled)\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Include the ResetValidationDataCallback in your training\n",
        "reset_val_callback = ResetValidationDataCallback(\n",
        "    validation_datagen=validation_datagen,\n",
        "    data_dir=data_dir,\n",
        "    img_height=img_height,\n",
        "    img_width=img_width,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Initialize the SaveBestEvery5Epochs callback\n",
        "save_best_callback = SaveBestEveryEpoch(save_dir=model_save_folder)\n",
        "\n",
        "# Initialize the confusion matrix callback\n",
        "conf_matrix_callback = ConfusionMatrixCallback(\n",
        "    validation_data=validation_generator,  # This is your validation data generator\n",
        "    class_indices=train_generator.class_indices  # This is the mapping of classes to indices\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model with the additional callback\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    initial_epoch=12,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[save_best_callback, lr_reducer, reset_val_callback, conf_matrix_callback]  # Add confusion matrix callback\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Save final model\n",
        "final_model_path_h5 = os.path.join(drive_folder, 'building_classifier_final.h5')\n",
        "model.save(final_model_path_h5)\n"
      ],
      "metadata": {
        "id": "23Q5fLxL1ZmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n"
      ],
      "metadata": {
        "id": "65p5yuXLh3H7",
        "outputId": "883ac0d7-b6be-4465-e94d-b73dbfd2cdb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating on full dataset"
      ],
      "metadata": {
        "id": "JSaRh3H91wOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import google.colab.drive as drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your Google Drive folder\n",
        "drive_folder = '/content/drive/MyDrive/Checkpoints/'\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/ModelsRes/model_epoch_17.h5'  # Path to your saved model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_height, img_width = 512, 512  # Adjust based on your model input\n",
        "batch_size = 256\n",
        "\n",
        "# Load the test dataset without augmentation\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/AIDataset',  # Path to your test dataset\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Change if using binary classification\n",
        "    shuffle=False  # Important for confusion matrix\n",
        ")\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = tf.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=test_generator.class_indices.keys(),\n",
        "            yticklabels=test_generator.class_indices.keys())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J-pJw0DHo_8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "55de06ca-7eb5-447b-d9db-a21d6d90f7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1c0082be45c7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_joblib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# joblib imports may raise DeprecationWarning on certain Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     from joblib import (\n\u001b[1;32m     11\u001b[0m         \u001b[0mMemory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}